#!/usr/bin/env python3.7

import os
import gym
import numpy as np
from stable_baselines3 import TD3
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.noise import NormalActionNoise

from mog_ai.gym_env import ApogeeGym
from mog_ai.catch_interface import CatchInterface
from mog_ai.callbacks import TensorboardCallback

def train():
    MODEL_DIR = os.getenv("TRAINING_DIR") + "TD3_models/"
    LOG_DIR = os.getenv("TRAINING_DIR") + "TD3_logs"
    interface = CatchInterface()
    env = ApogeeGym(interface)

    callback_list = []
    callback_list.append(TensorboardCallback())

    eval_callback = EvalCallback(env, best_model_save_path=MODEL_DIR, 
                                 log_path=LOG_DIR, deterministic=True,
                                 eval_freq=10, n_eval_episodes=1)
    callback_list.append(eval_callback)

    n_actions = env.action_space.shape[-1]
    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1*np.ones(n_actions))

    #model = TD3("MlpPolicy", env, action_noise=action_noise, verbose=1, tensorboard_log=LOG_DIR, learning_starts=500)
    model = TD3.load(MODEL_DIR + 'best_model', env=env, tensorboard_log=LOG_DIR)
    model.learn(total_timesteps=1000, callback=callback_list)
    model.save(MODEL_DIR + "TD3_Catch")




if __name__ == "__main__":
    train()
