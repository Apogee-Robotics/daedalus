#!/usr/bin/env python3.7

import os
import gym
from stable_baselines3 import TD3
from stable_baselines3.common.callbacks import EvalCallback

from mog_ai.gym_env import ApogeeGym
from mog_ai.catch_interface import CatchInterface
from mog_ai.callbacks import TensorboardCallback

def train():
    MODEL_DIR = os.getenv("TRAINING_DIR") + "TD3_models"
    LOG_DIR = os.getenv("TRAINING_DIR") + "TD3_logs"
    interface = CatchInterface()
    env = ApogeeGym(interface)

    callback_list = []
    callback_list.append(TensorboardCallback())

    eval_callback = EvalCallback(env, best_model_save_path=MODEL_DIR, 
                                 log_path=LOG_DIR, deterministic=True,
                                 eval_freq=10, n_eval_episodes=1)
    callback_list.append(eval_callback)

    model = TD3("MlpPolicy", env, verbose=1, tensorboard_log=LOG_DIR, learning_starts=500)

    model.learn(total_timesteps=1000, callback=callback_list)
    model.save(MODEL_DIR + "TD3_Catch")




if __name__ == "__main__":
    train()
