#!/home/cyborg/catkin_ws/src/daedalus/mog_ai/mog_venv/bin/python3
import gym
import rospy
import numpy as np
from stable_baselines3 import TD3

from stable_baselines3 import TD3
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.callbacks import StopTrainingOnMaxEpisodes
from stable_baselines3.common.noise import NormalActionNoise

from marsha_ai.catch_bandit.gym_env import MarshaGym
from marsha_ai.catch_bandit.catch_interface import CatchInterface
from mog_ai.callbacks import TensorboardCallback

import tensorflow as tf

MODEL_DIR = "/home/cyborg/catkin_ws/src/daedalus/mog_ai/training/models"
LOG_DIR = "/home/cyborg/catkin_ws/src/daedalus/mog_ai/training/logs"
EVAL_FREQUENCY = 50
N_EVAL_EP = 1

def train():
    interface = CatchInterface(training=True)
    env = MarshaGym(interface)

    
    callback_list = []
    callback_list.append(TensorboardCallback())

    eval_callback = EvalCallback(env, best_model_save_path=MODEL_DIR, log_path=LOG_DIR,
                            deterministic=True,
                            eval_freq=EVAL_FREQUENCY,
                            n_eval_episodes=N_EVAL_EP)

    callback_list.append(eval_callback)
    
    n_actions = env.action_space.shape[-1]
    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1*np.ones(n_actions))

    model = TD3("MlpPolicy", env, action_noise=action_noise, verbose=1, tensorboard_log=LOG_DIR, learning_starts=500)
    #model = TD3.load(MODEL_DIR + 'best_model', env=env, tensorboard_log=LOG_DIR)
    model.learn(total_timesteps=50000)

    model.save(MODEL_DIR + "TD3_Catch")

if __name__ == "__main__":
    train()
